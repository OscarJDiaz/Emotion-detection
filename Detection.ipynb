{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders found in train: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "Device: cuda\n",
      "Class weights: [1.0266047  9.406619   1.0010461  0.56843877 0.82603943 0.8491275\n",
      " 1.293373  ]\n",
      "[01] train_loss=1.7078 val_loss=1.4166 val_acc=0.4745 time=176.7s\n",
      "[02] train_loss=1.3820 val_loss=1.2900 val_acc=0.5258 time=19.2s\n",
      "[03] train_loss=1.3313 val_loss=1.2596 val_acc=0.5320 time=19.5s\n",
      "[04] train_loss=1.3360 val_loss=1.2614 val_acc=0.5064 time=21.8s\n",
      "[05] train_loss=1.2744 val_loss=1.4103 val_acc=0.4714 time=25.2s\n",
      "[06] train_loss=1.2720 val_loss=1.2540 val_acc=0.5213 time=22.6s\n",
      "[07] train_loss=1.2244 val_loss=1.2175 val_acc=0.5343 time=21.8s\n",
      "[08] train_loss=1.1982 val_loss=1.3475 val_acc=0.5059 time=21.1s\n",
      "[09] train_loss=1.1578 val_loss=1.8018 val_acc=0.4262 time=21.1s\n",
      "[10] train_loss=1.1553 val_loss=1.1791 val_acc=0.5598 time=21.2s\n",
      "[11] train_loss=1.0235 val_loss=1.1146 val_acc=0.5857 time=21.4s\n",
      "[12] train_loss=0.9611 val_loss=1.0870 val_acc=0.6031 time=22.1s\n",
      "[13] train_loss=0.9201 val_loss=1.0691 val_acc=0.6046 time=21.9s\n",
      "[14] train_loss=0.8586 val_loss=1.0544 val_acc=0.6091 time=21.9s\n",
      "[15] train_loss=0.7878 val_loss=1.0495 val_acc=0.6116 time=22.2s\n",
      "[16] train_loss=0.7230 val_loss=1.0231 val_acc=0.6315 time=22.4s\n",
      "[17] train_loss=0.6455 val_loss=1.0522 val_acc=0.6337 time=22.1s\n",
      "[18] train_loss=0.5855 val_loss=1.0779 val_acc=0.6374 time=22.3s\n",
      "[19] train_loss=0.5358 val_loss=1.0827 val_acc=0.6379 time=22.2s\n",
      "[20] train_loss=0.5144 val_loss=1.0808 val_acc=0.6358 time=22.0s\n",
      "Best val_acc: 0.6379214265812204\n"
     ]
    }
   ],
   "source": [
    "import os, math, copy, time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Rutas\n",
    "DATA_DIR = \"./FER-2013\"  # cambia si hace falta\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Clases esperadas (orden alfabetico para consistencia)\n",
    "CLASSES = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
    "\n",
    "# Transforms: convertimos a 48x48, pasamos a 3 canales para usar pesos preentrenados\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_ds = datasets.ImageFolder(TRAIN_DIR, transform=train_tf)\n",
    "test_ds  = datasets.ImageFolder(TEST_DIR,  transform=test_tf)\n",
    "\n",
    "# Asegura mapping de indices -> clases consistente\n",
    "# Si tus carpetas tienen otro orden lexicografico, reordenamos a CLASSES\n",
    "# Creamos un mapeo si faltan o hay typos\n",
    "idx_to_class = {v:k for k,v in train_ds.class_to_idx.items()}\n",
    "found = sorted(idx_to_class.values())\n",
    "print(\"Folders found in train:\", found)\n",
    "\n",
    "# DataLoaders (ajusta num_workers segun tu Colab; 2-4 suele ir bien)\n",
    "BATCH_SIZE = 128\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Calcular class weights para CrossEntropy (por desbalanceo)\n",
    "def compute_class_weights(dataset, num_classes):\n",
    "    counts = Counter([y for _,y in dataset.samples])\n",
    "    # dataset.samples guarda (path, class_idx); contamos por class_idx\n",
    "    freqs = np.array([counts[i] for i in range(num_classes)], dtype=np.float32)\n",
    "    weights = freqs.sum() / (freqs * num_classes)\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "class_weights = compute_class_weights(train_ds, num_classes).to(device)\n",
    "print(\"Class weights:\", class_weights.cpu().numpy())\n",
    "\n",
    "# Modelo: ResNet18 preentrenada\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Reemplazamos la ultima capa para 7 clases\n",
    "in_feats = model.fc.in_features\n",
    "model.fc = nn.Linear(in_feats, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizador y loss\n",
    "lr = 1e-3\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# One-cycle scheduler (opcional pero ayuda)\n",
    "steps_per_epoch = math.ceil(len(train_dl))\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-3,\n",
    "                                          steps_per_epoch=steps_per_epoch,\n",
    "                                          epochs=20)\n",
    "\n",
    "# Entrenamiento con early stopping\n",
    "EPOCHS = 20\n",
    "patience = 5\n",
    "best_acc = 0.0\n",
    "best_state = None\n",
    "no_improve = 0\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            loss_sum += loss.item() * y.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    start = time.time()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "    val_loss, val_acc = evaluate(test_dl)\n",
    "    dur = time.time() - start\n",
    "    print(f\"[{epoch:02d}] train_loss={train_loss:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f} time={dur:.1f}s\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_state = copy.deepcopy(model.state_dict())\n",
    "        no_improve = 0\n",
    "        torch.save(best_state, \"best_fer2013_resnet18.pt\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Cargar el mejor\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "print(\"Best val_acc:\", best_acc)\n",
    "\n",
    "# Guardar los pesos del modelo\n",
    "torch.save(model.state_dict(), \"best_fer2013_resnet18.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "\n",
    "# ===================== CONFIG =====================\n",
    "# Pon el nombre de tu fichero de pesos:\n",
    "WEIGHTS_PATH = \"best_fer2013_resnet18.pt\"\n",
    "\n",
    "# Lista de clases (en el mismo orden que usaste al entrenar)\n",
    "CLASSES = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n",
    "\n",
    "# Selecciona el preprocesado que COINCIDE con tu entrenamiento:\n",
    "# - Si entrenaste con tu script original: USE_IMAGENET_PREPROCESS = False\n",
    "# - Si entrenaste con mi patch (224 y mean/std ImageNet): USE_IMAGENET_PREPROCESS = True\n",
    "USE_IMAGENET_PREPROCESS = False\n",
    "\n",
    "# (Opcional) Usar detector de caras para recortar y clasificar solo la cara\n",
    "USE_FACE_DETECTOR = True\n",
    "\n",
    "# Umbral de confianza para mostrar etiqueta (0..1). Si es None, muestra siempre la top-1\n",
    "CONFIDENCE_THRESHOLD = 0.0\n",
    "\n",
    "# Dispositivo\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==================================================\n",
    "\n",
    "# --------- Transforms coherentes con el entrenamiento ---------\n",
    "if USE_IMAGENET_PREPROCESS:\n",
    "    # Patch sugerido: 224x224 + ImageNet mean/std\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std  = [0.229, 0.224, 0.225]\n",
    "    IMG_SIZE = (224, 224)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ])\n",
    "else:\n",
    "    # Tu código original: 48x48 + mean/std = 0.5\n",
    "    IMG_SIZE = (48, 48)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5]),\n",
    "    ])\n",
    "\n",
    "# --------- Modelo (ResNet18 con última capa a 7 clases) ---------\n",
    "def build_model(num_classes=7):\n",
    "    model = models.resnet18(pretrained=False)  # pretrained=True si quieres cargar ImageNet\n",
    "    in_feats = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feats, num_classes)\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes=len(CLASSES)).to(DEVICE)\n",
    "state = torch.load(WEIGHTS_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# --------- Detector de caras (opcional) ---------\n",
    "face_detector = None\n",
    "if USE_FACE_DETECTOR:\n",
    "    # Haar Cascade que viene con OpenCV\n",
    "    cascade_path = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "    face_detector = cv2.CascadeClassifier(cascade_path)\n",
    "\n",
    "# --------- Utilidades ---------\n",
    "def predict_emotion_bgr(face_bgr):\n",
    "    with torch.no_grad():\n",
    "        # 1) BGR -> GRAY\n",
    "        gray = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        # 2) GRAY -> RGB\n",
    "        rgb = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "        # 3) Resize\n",
    "        rgb = cv2.resize(rgb, IMG_SIZE, interpolation=cv2.INTER_LINEAR)\n",
    "        # 4) To tensor + normalize\n",
    "        x = preprocess(rgb).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "        prob, idx = torch.max(probs, dim=0)\n",
    "        return CLASSES[idx.item()], float(prob.item()), probs.detach().cpu().numpy()\n",
    "\n",
    "def draw_label(img, text, x, y):\n",
    "    \"\"\"Dibuja caja de texto con fondo.\"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale, thickness = 0.7, 2\n",
    "    (tw, th), _ = cv2.getTextSize(text, font, scale, thickness)\n",
    "    cv2.rectangle(img, (x, y - th - 8), (x + tw + 8, y + 4), (0, 0, 0), -1)\n",
    "    cv2.putText(img, text, (x + 4, y - 4), font, scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"No se pudo abrir la webcam.\")\n",
    "        return\n",
    "\n",
    "    # FPS\n",
    "    t0 = time.time()\n",
    "    frames = 0\n",
    "\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        frames += 1\n",
    "\n",
    "        display = frame.copy()\n",
    "\n",
    "        # Detección de rostro (opcional)\n",
    "        faces = []\n",
    "        if USE_FACE_DETECTOR and face_detector is not None:\n",
    "            gray_cam = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Parametros ajustables: scaleFactor y minNeighbors\n",
    "            rects = face_detector.detectMultiScale(gray_cam, scaleFactor=1.2, minNeighbors=5, minSize=(60, 60))\n",
    "            for (x, y, w, h) in rects:\n",
    "                faces.append((x, y, w, h))\n",
    "\n",
    "        if faces:\n",
    "            # Clasificar cada rostro detectado\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = frame[y:y+h, x:x+w]\n",
    "                label, prob, _ = predict_emotion_bgr(roi)\n",
    "                if (CONFIDENCE_THRESHOLD is None) or (prob >= CONFIDENCE_THRESHOLD):\n",
    "                    txt = f\"{label} ({prob*100:.1f}%)\"\n",
    "                else:\n",
    "                    txt = \"...\"\n",
    "\n",
    "                # Dibujar\n",
    "                cv2.rectangle(display, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                draw_label(display, txt, x, y)\n",
    "        else:\n",
    "            # Sin caras: clasificar el frame completo (fallback)\n",
    "            label, prob, _ = predict_emotion_bgr(frame)\n",
    "            H, W = frame.shape[:2]\n",
    "            if (CONFIDENCE_THRESHOLD is None) or (prob >= CONFIDENCE_THRESHOLD):\n",
    "                txt = f\"{label} ({prob*100:.1f}%)\"\n",
    "            else:\n",
    "                txt = \"...\"\n",
    "            # Caja centrada solo para referencia visual\n",
    "            box_w, box_h = int(0.4*W), int(0.4*H)\n",
    "            cx, cy = W//2, H//2\n",
    "            x1, y1 = cx - box_w//2, cy - box_h//2\n",
    "            x2, y2 = cx + box_w//2, cy + box_h//2\n",
    "            cv2.rectangle(display, (x1, y1), (x2, y2), (255, 200, 0), 2)\n",
    "            draw_label(display, txt, x1, y1)\n",
    "\n",
    "        # FPS\n",
    "        if frames % 10 == 0:\n",
    "            now = time.time()\n",
    "            fps = 10.0 / (now - t0)\n",
    "            t0 = now\n",
    "        # Evita recalcular si no ha tocado\n",
    "        fps_text = f\"FPS: {int(cap.get(cv2.CAP_PROP_FPS))}\" if cap.get(cv2.CAP_PROP_FPS) > 0 else \"\"\n",
    "\n",
    "        # Mostrar\n",
    "        if fps_text:\n",
    "            draw_label(display, fps_text, 10, 30)\n",
    "        cv2.imshow(\"FER2013 - Webcam Emotion\", display)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:  # 'q' o ESC para salir\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
